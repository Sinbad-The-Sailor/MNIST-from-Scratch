{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "\n",
    "An extention of logistic regression for non-binary classifcation is called softmax/multinomial regression. This can also be seen as a one layer neural network in and of itself.\n",
    "\n",
    "**MNIST** can be classifed from this methodology. \n",
    "\n",
    "In softmax regression we obtain a vector of probabilities for each $k \\in \\mathcal{C}$. This probability is obtained by applying the softmax function to the linear regression models for each class. That is\n",
    "\n",
    "$$\n",
    "\\sigma_{\\text{softmax}}: \\mathbb{R}^{n\\times1} \\rightarrow [0,1]^{K\\times 1}.\n",
    "$$\n",
    "\n",
    "The basic set up of using softmax regression is as follows:\n",
    "1. Have a list of all features/covariates $\\mathbf{x}$.\n",
    "2. Apply the linear regression for each class, i.e., $\\mathbf{w_i}^{\\text{T}}\\mathbf{x}~~i\\in\\{1,\\ldots,K\\}$.\n",
    "3. Apply the softmax function to the output vector of the different linear regression scoring models.\n",
    "4. Return the class which has the largest probability of being true.\n",
    "\n",
    "Parameter optimization is done via MLE. The process is slightly more involved than for logistic regression. Suppose we have a training set $\\mathcal{D} = \\{(\\mathbf{x}_i, \\mathbf{t}_i)\\}_{i=1}^n$. \n",
    "\n",
    "Each r.v. that is observed has some probability of being in a class $k \\in \\mathcal{C}$. Similarly to logistic regression we can write the probability of being in class $k$ given the obseervation $(\\mathbf{x}, \\mathbf{t}) \\in \\mathcal{D}$ and the weighting matrix $\\mathbf{W}$ as \n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Y = l| \\mathbf{x}, \\mathbf{W}) = p_1^{\\mathbb{1}_{\\{t_1 = l\\}}} \\cdot \\ldots \\cdot p_n^{\\mathbb{1}_{\\{t_n = l\\}}}\n",
    ".$$\n",
    "\n",
    "With an entire dataset $\\mathcal{D}$ we can derive a loss function using a likelihood based approach:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        L(\\mathbf{W}) \\triangleq p(\\mathcal{D}|\\mathbf{W}) & = \\mathbb{P}(Y_1 = t_1, \\ldots, Y_n = t_n|\\mathbf{W}) \\\\\n",
    "        & = \\mathbb{P}(Y_1 = t_1 | \\mathbf{W})\\ldots \\mathbb{P}(Y_n = t_n | \\mathbf{W})\\\\\n",
    "        & = \\prod_{i=1}^n \\prod_{l=1}^K \\Big[\\frac{\\exp{\\mathbf{w}_l^{\\text{T}}\\mathbf{x_i}}}{\\sum_{j=1}^K \\exp{\\mathbf{w}_j^{\\text{T}}\\mathbf{x_i}}} \\Big]^{\\mathbb{1}_{\\{t_l^{(i)} = l\\}}}.\n",
    "    \\end{split}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the mathematics slightly we introduce two new notations following Bishop. \n",
    "\n",
    "For a target vector $\\mathbf{t}_j$ we introduce a new matrix $\\mathbf{T} = [t_{ij}] \\in \\mathbb{R}^{n\\times K}$ which keeps track of the values in a target vector, raning from $j=1,...,K$ for each sample $i=1,...,n$.\n",
    "\n",
    "Secondly, we define \n",
    "$$\n",
    "y_l(\\mathbf{x}_i|\\mathbf{W}) \\triangleq \\frac{\\exp{\\mathbf{w}_l^{\\text{T}}\\mathbf{x_i}}}{\\sum_{j=1}^K \\exp{\\mathbf{w}_j^{\\text{T}}\\mathbf{x_i}}}.\n",
    "$$\n",
    "The likelihood function thus simplifies to \n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        L(\\mathbf{W}) \\triangleq p(\\mathcal{D}|\\mathbf{W}) & = \\mathbb{P}(Y_1 = t_1, \\ldots, Y_n = t_n|\\mathbf{W}) \\\\\n",
    "        & = \\prod_{i=1}^n \\prod_{l=1}^K \\Big[y_l(\\mathbf{x}_i|\\mathbf{W}) \\Big]^{t_{il}}.\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "Next, we obtain the cost function by the negative log-likelihood as\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "        \\mathcal{J}(\\mathbf{W}) \\triangleq - \\ln p(\\mathcal{D}|\\mathbf{W}) & = -\\sum_{i=1}^n \\sum_{l=1}^K t_{il} \\ln (y_l(\\mathbf{x}_i|\\mathbf{W})),\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "of which the gradients are calculated in the following manner\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}_j}\\mathcal{J}(\\mathbf{W}) = \\sum_{i=1}^N(y_j(\\mathbf{x}_i) - t_{ij})\\mathbf{x}_i \\in \\mathbb{R}^{M\\times 1},\n",
    "$$\n",
    "where $M$ is the number of features. However, we can simplify this to a greater extent, to obtain the following expression instead:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{W}}\\mathcal{J}(\\mathbf{W}) = (\\mathbf{Y}-\\mathbf{T})^{\\text{T}}\\mathbf{X},\n",
    "$$\n",
    "where $\\mathbf{Y}$ is the predicted values, $\\mathbf{T}$ are the target values which are one-hot-encoded, and $\\mathbf{X}$ are the input feature vectors stacked into a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model we do this without any regularization of $\\mathbf{W}$, and we use standard gradient decent, meaning \n",
    "\n",
    "$$\n",
    "\\mathbf{W}_{n+1} = \\mathbf{W}_n + \\eta \\nabla_{\\mathbf{W}}\\mathcal{J}(\\mathbf{W}).\n",
    "$$\n",
    "\n",
    "For some learning rate $\\eta$, which will be set as a constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plotting configuration.\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(['science', 'notebook', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing MNIST dataset. \n",
    "from mnist_utils.data_reader import (TESTING_DATA,\n",
    "                                     TESTING_LABELS,\n",
    "                                     TRAINING_DATA,\n",
    "                                     TRAINING_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 245,
       "width": 248
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(TRAINING_DATA[250])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Configuring Data and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(array: np.array) -> np.array:\n",
    "    \n",
    "    data_length = len(array)\n",
    "    feature_length = max(array) + 1\n",
    "    dim  = (data_length, feature_length)\n",
    "    one_hot_matrix = np.zeros(dim)\n",
    "\n",
    "    for i in range(data_length):\n",
    "        digit = array[i]\n",
    "        one_hot_matrix[i][digit] = 1\n",
    "\n",
    "    return one_hot_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec(matrix: np.array) -> np.array:\n",
    "    vec_matrix = np.zeros(0)\n",
    "    \n",
    "    return np.append(vec_matrix, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.array, W: np.array) -> np.array:\n",
    "    score_vector = np.exp(W @ x.T - np.max(W @ x.T))\n",
    "    normalizing_constant = np.sum(score_vector)\n",
    "\n",
    "    return score_vector / normalizing_constant\n",
    "\n",
    "def _Y_matrix(X: np.array, W: np.array) -> np.array:\n",
    "    Y = []\n",
    "    for x_data in X:\n",
    "        Y.append(softmax(x_data, W))\n",
    "    Y = np.stack(Y)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = one_hot_encoding(TRAINING_LABELS)\n",
    "\n",
    "x_values = []\n",
    "for digit in TRAINING_DATA:\n",
    "    x_values.append(vec(digit))\n",
    "ones = np.ones(60000)\n",
    "X = np.stack(x_values)/255\n",
    "X = np.insert(x_values, 0, ones, axis=1)\n",
    "\n",
    "# Initial weight matrix W.\n",
    "dim = (10, np.shape(X)[1])\n",
    "W = np.random.uniform(-0.000000001, 0.000000001, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Cost Function and Jacobian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-32\n",
    "\n",
    "def cost(X: np.array, T: np.array, W: np.array) -> float:\n",
    "    cost = 0\n",
    "    dim = np.shape(T)\n",
    "    Y = _Y_matrix(X, W)\n",
    "\n",
    "    number_of_observations = dim[0]\n",
    "    number_of_categories = dim[1]\n",
    "\n",
    "    for i in range(number_of_observations):\n",
    "        for j in range(number_of_categories):\n",
    "            cost = cost - T[i][j] * np.log(Y[i][j]+ EPSILON)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X: np.array, T: np.array, W: np.array) -> np.array:\n",
    "    Y = _Y_matrix(X, W)\n",
    "    return (Y-T).T @ X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "----------------------------------------\n",
      "Loss:                             138155\n",
      "Max Weight:            19501.89091875007\n",
      "Min Weight:          -16256.232333640153\n",
      "\n",
      "Epoch: 2/100\n",
      "----------------------------------------\n",
      "Loss:                            1451033\n",
      "Max Weight:           26865.354860027444\n",
      "Min Weight:          -28835.203990854683\n",
      "\n",
      "Epoch: 3/100\n",
      "----------------------------------------\n",
      "Loss:                            3020844\n",
      "Max Weight:            40046.40686820743\n",
      "Min Weight:           -99299.07292460505\n",
      "\n",
      "Epoch: 4/100\n",
      "----------------------------------------\n",
      "Loss:                            2387688\n",
      "Max Weight:            49966.41363409664\n",
      "Min Weight:           -84033.51292460505\n",
      "\n",
      "Epoch: 5/100\n",
      "----------------------------------------\n",
      "Loss:                            2541906\n",
      "Max Weight:           61997.133634096645\n",
      "Min Weight:           -72312.51027575595\n",
      "\n",
      "Epoch: 6/100\n",
      "----------------------------------------\n",
      "Loss:                            2612494\n",
      "Max Weight:            60789.73555697258\n",
      "Min Weight:           -87507.38685745547\n",
      "\n",
      "Epoch: 7/100\n",
      "----------------------------------------\n",
      "Loss:                            2587589\n",
      "Max Weight:            75706.63363409665\n",
      "Min Weight:           -83077.86685745546\n",
      "\n",
      "Epoch: 8/100\n",
      "----------------------------------------\n",
      "Loss:                            2130314\n",
      "Max Weight:            69014.75363409665\n",
      "Min Weight:           -78979.21886920274\n",
      "\n",
      "Epoch: 9/100\n",
      "----------------------------------------\n",
      "Loss:                            2336626\n",
      "Max Weight:            77070.08560095876\n",
      "Min Weight:           -74926.43886920274\n",
      "\n",
      "Epoch: 10/100\n",
      "----------------------------------------\n",
      "Loss:                            2608736\n",
      "Max Weight:            83134.86502606023\n",
      "Min Weight:           -70873.65886920274\n",
      "\n",
      "Epoch: 11/100\n",
      "----------------------------------------\n",
      "Loss:                            1473875\n",
      "Max Weight:              75240.932829652\n",
      "Min Weight:           -84719.95886920275\n",
      "\n",
      "Epoch: 12/100\n",
      "----------------------------------------\n",
      "Loss:                            1498117\n",
      "Max Weight:              74217.892829652\n",
      "Min Weight:           -82814.45886920275\n",
      "\n",
      "Epoch: 13/100\n",
      "----------------------------------------\n",
      "Loss:                            1343457\n",
      "Max Weight:            78489.78560095877\n",
      "Min Weight:           -89471.37886920274\n",
      "\n",
      "Epoch: 14/100\n",
      "----------------------------------------\n",
      "Loss:                             794226\n",
      "Max Weight:            77612.70560095877\n",
      "Min Weight:           -86830.63886920274\n",
      "\n",
      "Epoch: 15/100\n",
      "----------------------------------------\n",
      "Loss:                             739921\n",
      "Max Weight:            78390.56560095877\n",
      "Min Weight:           -85845.29886920274\n",
      "\n",
      "Epoch: 16/100\n",
      "----------------------------------------\n",
      "Loss:                             701164\n",
      "Max Weight:            76808.08560095877\n",
      "Min Weight:           -84294.51886920274\n",
      "\n",
      "Epoch: 17/100\n",
      "----------------------------------------\n",
      "Loss:                             715017\n",
      "Max Weight:            76600.62560095877\n",
      "Min Weight:           -83216.31886920275\n",
      "\n",
      "Epoch: 18/100\n",
      "----------------------------------------\n",
      "Loss:                             691512\n",
      "Max Weight:            75237.16560095876\n",
      "Min Weight:           -81817.37886920274\n",
      "\n",
      "Epoch: 19/100\n",
      "----------------------------------------\n",
      "Loss:                             723048\n",
      "Max Weight:            74733.30560095876\n",
      "Min Weight:           -80729.69886920275\n",
      "\n",
      "Epoch: 20/100\n",
      "----------------------------------------\n",
      "Loss:                             701754\n",
      "Max Weight:            73485.40560095877\n",
      "Min Weight:           -79405.33886920275\n",
      "\n",
      "Epoch: 21/100\n",
      "----------------------------------------\n",
      "Loss:                             756942\n",
      "Max Weight:            74203.61282965199\n",
      "Min Weight:           -78281.89886920275\n",
      "\n",
      "Epoch: 22/100\n",
      "----------------------------------------\n",
      "Loss:                             757237\n",
      "Max Weight:            71755.04560095877\n",
      "Min Weight:           -77083.63886920275\n",
      "\n",
      "Epoch: 23/100\n",
      "----------------------------------------\n",
      "Loss:                             851330\n",
      "Max Weight:            74914.85282965198\n",
      "Min Weight:           -75998.81886920275\n",
      "\n",
      "Epoch: 24/100\n",
      "----------------------------------------\n",
      "Loss:                             841604\n",
      "Max Weight:            69581.84560095877\n",
      "Min Weight:           -74724.07886920274\n",
      "\n",
      "Epoch: 25/100\n",
      "----------------------------------------\n",
      "Loss:                             955296\n",
      "Max Weight:            75448.67282965197\n",
      "Min Weight:           -73934.07886920274\n",
      "\n",
      "Epoch: 26/100\n",
      "----------------------------------------\n",
      "Loss:                             882350\n",
      "Max Weight:            67158.18560095876\n",
      "Min Weight:           -72310.31886920275\n",
      "\n",
      "Epoch: 27/100\n",
      "----------------------------------------\n",
      "Loss:                             776836\n",
      "Max Weight:            74702.37282965197\n",
      "Min Weight:           -72641.63886920275\n",
      "\n",
      "Epoch: 28/100\n",
      "----------------------------------------\n",
      "Loss:                             736458\n",
      "Max Weight:            65195.37282965197\n",
      "Min Weight:           -70568.97886920275\n",
      "\n",
      "Epoch: 29/100\n",
      "----------------------------------------\n",
      "Loss:                             717964\n",
      "Max Weight:            73615.47282965198\n",
      "Min Weight:           -71930.05886920275\n",
      "\n",
      "Epoch: 30/100\n",
      "----------------------------------------\n",
      "Loss:                             706912\n",
      "Max Weight:            66586.45282965197\n",
      "Min Weight:           -69202.31886920275\n",
      "\n",
      "Epoch: 31/100\n",
      "----------------------------------------\n",
      "Loss:                             761805\n",
      "Max Weight:            73625.60560095876\n",
      "Min Weight:           -73679.45886920275\n",
      "\n",
      "Epoch: 32/100\n",
      "----------------------------------------\n",
      "Loss:                             952938\n",
      "Max Weight:            67540.93282965198\n",
      "Min Weight:           -69795.41886920275\n",
      "\n",
      "Epoch: 33/100\n",
      "----------------------------------------\n",
      "Loss:                             953822\n",
      "Max Weight:            77611.48560095875\n",
      "Min Weight:           -79989.75886920275\n",
      "\n",
      "Epoch: 34/100\n",
      "----------------------------------------\n",
      "Loss:                             807710\n",
      "Max Weight:            67339.41282965199\n",
      "Min Weight:           -76275.89886920275\n",
      "\n",
      "Epoch: 35/100\n",
      "----------------------------------------\n",
      "Loss:                             834898\n",
      "Max Weight:            87666.64560095874\n",
      "Min Weight:           -83948.67886920275\n",
      "\n",
      "Epoch: 36/100\n",
      "----------------------------------------\n",
      "Loss:                            1040326\n",
      "Max Weight:            67523.52403869864\n",
      "Min Weight:           -79928.87886920274\n",
      "\n",
      "Epoch: 37/100\n",
      "----------------------------------------\n",
      "Loss:                             952570\n",
      "Max Weight:            89577.04560095875\n",
      "Min Weight:           -93425.11886920275\n",
      "\n",
      "Epoch: 38/100\n",
      "----------------------------------------\n",
      "Loss:                             709343\n",
      "Max Weight:            87211.94560095874\n",
      "Min Weight:           -89753.27886920275\n",
      "\n",
      "Epoch: 39/100\n",
      "----------------------------------------\n",
      "Loss:                             649439\n",
      "Max Weight:            91473.08560095874\n",
      "Min Weight:           -89005.13886920275\n",
      "\n",
      "Epoch: 40/100\n",
      "----------------------------------------\n",
      "Loss:                             711111\n",
      "Max Weight:            87436.94560095874\n",
      "Min Weight:           -87149.93886920276\n",
      "\n",
      "Epoch: 41/100\n",
      "----------------------------------------\n",
      "Loss:                             818836\n",
      "Max Weight:            90295.02560095875\n",
      "Min Weight:           -86160.23886920276\n",
      "\n",
      "Epoch: 42/100\n",
      "----------------------------------------\n",
      "Loss:                             851698\n",
      "Max Weight:            86339.46560095875\n",
      "Min Weight:           -84525.37886920276\n",
      "\n",
      "Epoch: 43/100\n",
      "----------------------------------------\n",
      "Loss:                             792089\n",
      "Max Weight:            88034.04560095875\n",
      "Min Weight:           -83816.71886920276\n",
      "\n",
      "Epoch: 44/100\n",
      "----------------------------------------\n",
      "Loss:                             809404\n",
      "Max Weight:            84039.96560095875\n",
      "Min Weight:           -82334.31886920276\n",
      "\n",
      "Epoch: 45/100\n",
      "----------------------------------------\n",
      "Loss:                             848677\n",
      "Max Weight:            86555.30560095875\n",
      "Min Weight:           -81599.11886920276\n",
      "\n",
      "Epoch: 46/100\n",
      "----------------------------------------\n",
      "Loss:                             830256\n",
      "Max Weight:            81759.20560095874\n",
      "Min Weight:           -80052.77886920277\n",
      "\n",
      "Epoch: 47/100\n",
      "----------------------------------------\n",
      "Loss:                             844404\n",
      "Max Weight:            84974.94560095874\n",
      "Min Weight:           -79667.43886920277\n",
      "\n",
      "Epoch: 48/100\n",
      "----------------------------------------\n",
      "Loss:                             798204\n",
      "Max Weight:            79522.10560095875\n",
      "Min Weight:           -78060.73886920277\n",
      "\n",
      "Epoch: 49/100\n",
      "----------------------------------------\n",
      "Loss:                             801520\n",
      "Max Weight:            83054.90560095875\n",
      "Min Weight:           -77904.67886920278\n",
      "\n",
      "Epoch: 50/100\n",
      "----------------------------------------\n",
      "Loss:                             745669\n",
      "Max Weight:            77751.02560095875\n",
      "Min Weight:           -76189.75886920278\n",
      "\n",
      "Epoch: 51/100\n",
      "----------------------------------------\n",
      "Loss:                             737269\n",
      "Max Weight:            80823.00560095874\n",
      "Min Weight:           -76231.83886920278\n",
      "\n",
      "Epoch: 52/100\n",
      "----------------------------------------\n",
      "Loss:                             681049\n",
      "Max Weight:            76211.84560095874\n",
      "Min Weight:           -74537.03886920278\n",
      "\n",
      "Epoch: 53/100\n",
      "----------------------------------------\n",
      "Loss:                             658723\n",
      "Max Weight:            78511.18560095874\n",
      "Min Weight:           -74573.57886920277\n",
      "\n",
      "Epoch: 54/100\n",
      "----------------------------------------\n",
      "Loss:                             607808\n",
      "Max Weight:            74896.24560095873\n",
      "Min Weight:           -73071.30920161353\n",
      "\n",
      "Epoch: 55/100\n",
      "----------------------------------------\n",
      "Loss:                             559325\n",
      "Max Weight:            76112.48560095874\n",
      "Min Weight:           -73176.78920161353\n",
      "\n",
      "Epoch: 56/100\n",
      "----------------------------------------\n",
      "Loss:                             525947\n",
      "Max Weight:            73414.56560095874\n",
      "Min Weight:           -71924.16920161353\n",
      "\n",
      "Epoch: 57/100\n",
      "----------------------------------------\n",
      "Loss:                             484905\n",
      "Max Weight:            73786.40560095874\n",
      "Min Weight:           -71779.02920161354\n",
      "\n",
      "Epoch: 58/100\n",
      "----------------------------------------\n",
      "Loss:                             470832\n",
      "Max Weight:            71659.66560095873\n",
      "Min Weight:           -70721.18920161354\n",
      "\n",
      "Epoch: 59/100\n",
      "----------------------------------------\n",
      "Loss:                             454046\n",
      "Max Weight:            71657.20560095872\n",
      "Min Weight:           -70417.88920161354\n",
      "\n",
      "Epoch: 60/100\n",
      "----------------------------------------\n",
      "Loss:                             452411\n",
      "Max Weight:            69868.78560095873\n",
      "Min Weight:           -69500.30920161353\n",
      "\n",
      "Epoch: 61/100\n",
      "----------------------------------------\n",
      "Loss:                             442674\n",
      "Max Weight:            69699.98560095872\n",
      "Min Weight:           -69095.80920161353\n",
      "\n",
      "Epoch: 62/100\n",
      "----------------------------------------\n",
      "Loss:                             443422\n",
      "Max Weight:            68081.00560095873\n",
      "Min Weight:           -68252.64920161353\n",
      "\n",
      "Epoch: 63/100\n",
      "----------------------------------------\n",
      "Loss:                             438191\n",
      "Max Weight:            67869.56560095873\n",
      "Min Weight:           -67832.68920161352\n",
      "\n",
      "Epoch: 64/100\n",
      "----------------------------------------\n",
      "Loss:                             437159\n",
      "Max Weight:            67209.48017928784\n",
      "Min Weight:           -67043.72920161352\n",
      "\n",
      "Epoch: 65/100\n",
      "----------------------------------------\n",
      "Loss:                             433696\n",
      "Max Weight:            67347.30017928785\n",
      "Min Weight:           -66626.10920161352\n",
      "\n",
      "Epoch: 66/100\n",
      "----------------------------------------\n",
      "Loss:                             432370\n",
      "Max Weight:            67378.84017928784\n",
      "Min Weight:           -65837.88920161352\n",
      "\n",
      "Epoch: 67/100\n",
      "----------------------------------------\n",
      "Loss:                             428538\n",
      "Max Weight:            67507.32017928784\n",
      "Min Weight:           -65437.56920161352\n",
      "\n",
      "Epoch: 68/100\n",
      "----------------------------------------\n",
      "Loss:                             428980\n",
      "Max Weight:            67535.70017928784\n",
      "Min Weight:           -64651.60920161352\n",
      "\n",
      "Epoch: 69/100\n",
      "----------------------------------------\n",
      "Loss:                             424265\n",
      "Max Weight:            67670.04017928784\n",
      "Min Weight:           -64326.66920161352\n",
      "\n",
      "Epoch: 70/100\n",
      "----------------------------------------\n",
      "Loss:                             426844\n",
      "Max Weight:            67668.40017928784\n",
      "Min Weight:           -63501.70920161352\n",
      "\n",
      "Epoch: 71/100\n",
      "----------------------------------------\n",
      "Loss:                             423454\n",
      "Max Weight:            67812.14017928785\n",
      "Min Weight:           -63248.78920161352\n",
      "\n",
      "Epoch: 72/100\n",
      "----------------------------------------\n",
      "Loss:                             424633\n",
      "Max Weight:            67759.20017928784\n",
      "Min Weight:           -62330.78920161352\n",
      "\n",
      "Epoch: 73/100\n",
      "----------------------------------------\n",
      "Loss:                             429717\n",
      "Max Weight:            67939.92017928784\n",
      "Min Weight:           -62266.46920161352\n",
      "\n",
      "Epoch: 74/100\n",
      "----------------------------------------\n",
      "Loss:                             433107\n",
      "Max Weight:            67837.00017928785\n",
      "Min Weight:          -61455.262557589725\n",
      "\n",
      "Epoch: 75/100\n",
      "----------------------------------------\n",
      "Loss:                             446885\n",
      "Max Weight:            68094.16017928785\n",
      "Min Weight:           -61603.06255758973\n",
      "\n",
      "Epoch: 76/100\n",
      "----------------------------------------\n",
      "Loss:                             485348\n",
      "Max Weight:            67828.38017928785\n",
      "Min Weight:           -60958.50255758973\n",
      "\n",
      "Epoch: 77/100\n",
      "----------------------------------------\n",
      "Loss:                             606998\n",
      "Max Weight:            68286.48017928786\n",
      "Min Weight:           -62524.80255758973\n",
      "\n",
      "Epoch: 78/100\n",
      "----------------------------------------\n",
      "Loss:                            1059262\n",
      "Max Weight:            67372.82017928785\n",
      "Min Weight:           -61526.96255758974\n",
      "\n",
      "Epoch: 79/100\n",
      "----------------------------------------\n",
      "Loss:                            1915750\n",
      "Max Weight:            75199.33091875003\n",
      "Min Weight:           -66374.82255758974\n",
      "\n",
      "Epoch: 80/100\n",
      "----------------------------------------\n",
      "Loss:                            1113419\n",
      "Max Weight:            72796.14560095871\n",
      "Min Weight:           -65356.72255758974\n",
      "\n",
      "Epoch: 81/100\n",
      "----------------------------------------\n",
      "Loss:                            1167355\n",
      "Max Weight:            70165.10017928785\n",
      "Min Weight:           -65227.22255758974\n",
      "\n",
      "Epoch: 82/100\n",
      "----------------------------------------\n",
      "Loss:                            1467833\n",
      "Max Weight:            79589.58560095872\n",
      "Min Weight:           -69945.34920161353\n",
      "\n",
      "Epoch: 83/100\n",
      "----------------------------------------\n",
      "Loss:                            1919066\n",
      "Max Weight:            72813.80017928785\n",
      "Min Weight:           -68677.65046741819\n",
      "\n",
      "Epoch: 84/100\n",
      "----------------------------------------\n",
      "Loss:                            1454202\n",
      "Max Weight:            78076.48560095872\n",
      "Min Weight:           -82431.24255758974\n",
      "\n",
      "Epoch: 85/100\n",
      "----------------------------------------\n",
      "Loss:                            1535179\n",
      "Max Weight:            96923.56560095873\n",
      "Min Weight:           -81374.76255758974\n",
      "\n",
      "Epoch: 86/100\n",
      "----------------------------------------\n",
      "Loss:                            1001790\n",
      "Max Weight:            76115.34017928784\n",
      "Min Weight:           -80675.88255758974\n",
      "\n",
      "Epoch: 87/100\n",
      "----------------------------------------\n",
      "Loss:                             946380\n",
      "Max Weight:            98498.20560095872\n",
      "Min Weight:           -84725.10255758974\n",
      "\n",
      "Epoch: 88/100\n",
      "----------------------------------------\n",
      "Loss:                            1001200\n",
      "Max Weight:            81594.68560095872\n",
      "Min Weight:           -83796.76255758974\n",
      "\n",
      "Epoch: 89/100\n",
      "----------------------------------------\n",
      "Loss:                             852288\n",
      "Max Weight:           105285.30560095872\n",
      "Min Weight:           -94540.91886920278\n",
      "\n",
      "Epoch: 90/100\n",
      "----------------------------------------\n",
      "Loss:                             672649\n",
      "Max Weight:            98850.04560095872\n",
      "Min Weight:           -90646.01886920279\n",
      "\n",
      "Epoch: 91/100\n",
      "----------------------------------------\n",
      "Loss:                             540978\n",
      "Max Weight:           105526.98560095872\n",
      "Min Weight:           -92151.31886920279\n",
      "\n",
      "Epoch: 92/100\n",
      "----------------------------------------\n",
      "Loss:                             489253\n",
      "Max Weight:           101759.06560095873\n",
      "Min Weight:            -89981.4788692028\n",
      "\n",
      "Epoch: 93/100\n",
      "----------------------------------------\n",
      "Loss:                             459043\n",
      "Max Weight:           102244.86560095873\n",
      "Min Weight:           -89250.53886920279\n",
      "\n",
      "Epoch: 94/100\n",
      "----------------------------------------\n",
      "Loss:                             454622\n",
      "Max Weight:           100659.34560095872\n",
      "Min Weight:            -87907.6388692028\n",
      "\n",
      "Epoch: 95/100\n",
      "----------------------------------------\n",
      "Loss:                             448212\n",
      "Max Weight:            99817.32560095872\n",
      "Min Weight:           -86870.36255758973\n",
      "\n",
      "Epoch: 96/100\n",
      "----------------------------------------\n",
      "Loss:                             444380\n",
      "Max Weight:            98643.96560095872\n",
      "Min Weight:           -86570.72255758973\n",
      "\n",
      "Epoch: 97/100\n",
      "----------------------------------------\n",
      "Loss:                             440327\n",
      "Max Weight:            97538.12560095872\n",
      "Min Weight:           -86268.98255758973\n",
      "\n",
      "Epoch: 98/100\n",
      "----------------------------------------\n",
      "Loss:                             437528\n",
      "Max Weight:            96437.66560095872\n",
      "Min Weight:           -85980.12255758973\n",
      "\n",
      "Epoch: 99/100\n",
      "----------------------------------------\n",
      "Loss:                             437749\n",
      "Max Weight:            95376.58560095872\n",
      "Min Weight:           -85664.44255758973\n",
      "\n",
      "Epoch: 100/100\n",
      "----------------------------------------\n",
      "Loss:                             431707\n",
      "Max Weight:            94289.42560095871\n",
      "Min Weight:           -85355.82255758974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_ITERATIONS = 100\n",
    "LEARNING_RATE = -0.02\n",
    "\n",
    "for i in range(NUMBER_OF_ITERATIONS):\n",
    "    # LOSS\n",
    "    current_cost = cost(X, T, W)\n",
    "    # Update weight\n",
    "    W = W + LEARNING_RATE * gradient(X, T, W)\n",
    "    print(f\"Epoch: {i+1}/{NUMBER_OF_ITERATIONS}\".ljust(1))\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Loss: \" + str(int(current_cost)).rjust(34))\n",
    "    print(\"Max Weight: \" + str(np.max(W)).rjust(28))\n",
    "    print(\"Min Weight: \" + str(np.min(W)).rjust(28) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "i = 233\n",
    "s = np.insert(TRAINING_DATA[i], 0, 1)\n",
    "print(softmax(s, W))\n",
    "print(TRAINING_LABELS[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dff8b73526701c08e8c4b8ff311f76facea885c22db9ac0534f1f6f35e78fb53"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
